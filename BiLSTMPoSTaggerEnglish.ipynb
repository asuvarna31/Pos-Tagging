{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTMPoSTaggerEnglish.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPoCVvDgtkBUDfXdqLF1wGS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asuvarna31/Pos-Tagging/blob/master/BiLSTMPoSTaggerEnglish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEZ6yvfzo3Kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext import datasets #already prepped datasets English\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "import time\n",
        "import random #used for random seeding data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_mo0Dovp1in",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field (lower = True)\n",
        "PTB_Tags = data.Field (unk_token = None) #remove the default unk_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeXUOh8BrEzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fields = ((\"text\", TEXT), (None, None) ,(\"ptbtags\", PTB_Tags))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6glJLqFMrd27",
        "colab_type": "text"
      },
      "source": [
        "Load the PTBPOS dataset and use fields to pass our fields to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKqcVRlErYGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1dd8152f-1af0-4f09-8d26-a2d4fe15573f"
      },
      "source": [
        "train_data, val_data, test_data = datasets.UDPOS.splits(fields)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading en-ud-v2.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "en-ud-v2.zip: 100%|██████████| 688k/688k [00:00<00:00, 2.06MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYXNMtmasDVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "73bc30a8-4f51-4a2e-cf2d-8ee4eb94c84e"
      },
      "source": [
        " #min_frequency of words to be added in vocabulary = 2\n",
        "\n",
        "TEXT.build_vocab(train_data, min_freq =2, vectors = \"glove.6B.100d\",unk_init = torch.Tensor.normal_ )\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:26, 2.23MB/s]                          \n",
            "100%|█████████▉| 399934/400000 [00:17<00:00, 23417.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b25ec0021d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"glove.6B.100d\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mPTB_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'PTB_tags' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RSWYv1Vwdig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PTB_Tags.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8MRqjnqsvyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1024\n",
        "random.seed (SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4ikNrmvtP9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SZ = 128\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_iterator, val_iterator, test_iterator = data.BucketIterator.splits ((train_data, val_data, test_data), batch_size = BATCH_SZ, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TudOD6Y8t6aj",
        "colab_type": "text"
      },
      "source": [
        "Model used for PoS-Tagging - a multi-layer bi-directional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrFLj-w3t4r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
        "      super().__init__()\n",
        "      self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
        "\n",
        "      self.lstm = nn.LSTM (embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          dropout = dropout if n_layers > 1 else 0)\n",
        "      self.fc = nn.Linear (hidden_dim*2 if bidirectional else hidden_dim, output_dim)\n",
        "      self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward (self, text):\n",
        "      embedded = self.dropout(self.embedding(text))\n",
        "      outputs, (hidden,cell) = self.lstm(embedded)\n",
        "      predictions = self.fc(self.dropout(outputs))\n",
        "      return predictions\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc2juuWrwn8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Input_dim = len(TEXT.vocab)\n",
        "Embedding_dim = 100\n",
        "Hidden_dim = 128\n",
        "Output_dim = len(PTB_Tags.vocab)\n",
        "n_layers = 3\n",
        "Bidirectional = True\n",
        "Dropout = 0.25\n",
        "Pad_Idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = BiLSTM (Input_dim, Embedding_dim, Hidden_dim, Output_dim, n_layers, Bidirectional, Dropout, Pad_Idx)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKagKDSRymYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d83cefc1-d6b6-440b-a246-8779ee40b61c"
      },
      "source": [
        "def init_wts(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
        "        \n",
        "model.apply(init_wts)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM(\n",
              "  (embedding): Embedding(8866, 100, padding_idx=1)\n",
              "  (lstm): LSTM(100, 128, num_layers=3, dropout=0.25, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=51, bias=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAi9oIvGyVmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "model.embedding.weight.data[Pad_Idx] = torch.zeros(Embedding_dim) #initialize pad tokens to zeroes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MN423TezdVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "TAG_PAD_IDX = PTB_Tags.vocab.stoi[PTB_Tags.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGd8_WMm0qoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxtwBopL0zHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_accuracy(preds, y, tag_pad_idx):\n",
        "   #skip accuracy calculations over <pad> tokens\n",
        "   max_pred = preds.argmax(dim=1, keepdim=True)\n",
        "   non_pad_elements = (y != tag_pad_idx).nonzero() #stores all non-pad elements\n",
        "   correct = max_pred[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
        "   return correct.sum()/torch.FloatTensor([y[non_pad_elements].shape[0]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-1wnrUE1o1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "      text = batch.text\n",
        "      tags = batch.ptbtags\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      predictions = model(text)\n",
        "      \n",
        "      predictions = predictions.view(-1,predictions.shape[-1])\n",
        "      tags = tags.view(-1)\n",
        "      \n",
        "      loss = criterion(predictions, tags)\n",
        "      acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "        \n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6GmfF2N2bna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "          text = batch.text\n",
        "          tags = batch.ptbtags\n",
        "\n",
        "          predictions = model(text)\n",
        "\n",
        "          predictions = predictions.view(-1,predictions.shape[-1])\n",
        "          tags = tags.view(-1)\n",
        "          \n",
        "          loss = criterion(predictions, tags)\n",
        "          acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "          \n",
        "            \n",
        "          epoch_loss += loss.item()\n",
        "          epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPaKH4Cd3DMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_epochs = 10\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range (N_epochs):\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
        "  valid_loss, valid_acc = evaluate(model, val_iterator, criterion, TAG_PAD_IDX)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "  print(f'Epoch: {epoch+1:02}')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8kvrbf346OD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}